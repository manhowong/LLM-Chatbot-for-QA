{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slack Bot Demo\n",
    "\n",
    "This is the demo version of the Slack Bot, \"Genius\". You can run this file locally. If you would like to access the Slack Bot deployed on Slack, please inform me and I will invite you to my Slack Workplace. Since the bot is hosted locally on my computer, please provide the specific time you plan to access the bot so that I can run a development server and establish the connection with Slack.\n",
    "\n",
    "> #### Atenttion!!!\n",
    ">\n",
    "> **About API keys and tokens**\n",
    "> - **Slack:**\n",
    "> The Slack bot uses my API keys. The keys may expire or exceed the request limits at any time...\n",
    "> - **This file:**\n",
    "> To run this file, please provide your API keys and access tokens in a `.env` file. *(see [template.env](template.env))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Set up the environment\n",
    "\n",
    "We will first need to import the required packages, load the API keys from `.env` file, and set the language model and the embedding model.\n",
    "\n",
    "> **Notes**\n",
    "> - I was using OpenAI's models originally, but had to switch to AI21's LLM and Cohere's embedding model because my free trial account conveniently expired...\n",
    "> - I am using models from two companies so that I won't send too many requests to one service too frequently and exeed my call limits...\n",
    "> - I think OpenAI's models perform a bit more accurate, but repond slightly slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import flatdict  # flattens nested dict\n",
    "import re\n",
    "\n",
    "# packages for web scraping/ searching\n",
    "import validators\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time  # gives extra time for webdriver to load webpage\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Language models and embedding models\n",
    "# from langchain.llms import OpenAI  # my OpenAI trial expired :/\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# from langchain.llms import Cohere\n",
    "from langchain.llms import AI21\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "# Chains and chain components\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.tools import tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Load api key variables from .env file and set api keys\n",
    "load_dotenv(find_dotenv('private/.env'))\n",
    "SERPAPI_API_KEY = os.environ[\"SERPAPI_API_KEY\"]\n",
    "AI21_API_KEY = os.environ[\"AI21_API_KEY\"]\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]\n",
    "\n",
    "# Set language model\n",
    "# llm = OpenAI(temperature=0)\n",
    "llm = AI21(temperature=0.5)\n",
    "llm_doc = AI21(temperature=0.1)  # for queries related to docs\n",
    "\n",
    "# Rate limit for Cohere model is 5 calls/min\n",
    "# llm = Cohere(temperature=0.5)\n",
    "# llm_doc = Cohere(temperature=0)  # for queries related to docs\n",
    "\n",
    "# Get Cohere embedding model\n",
    "embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Set up the base vector store\n",
    "\n",
    "The base vector store contains basic information about Home Depot's services and products. It will help the bot to decide whether a query is relavant. New texts and documents can be added to this vector store later.\n",
    "\n",
    "In this step, I will index Home Depot's [site map](https://www.homedepot.com/c/site_map) to get the information needed. I will first scrape the texts from the web page and then store the texts in a Chroma vector store.\n",
    "\n",
    "> **Notes**: Home Depot server rejects requests from / delays responses to unknown users. To bypass that restriction, see the script below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Home Depot's site map to get a list of services and products\n",
    "\n",
    "# Home Depot server rejects requests from / delays responses to unknown users. Need the headers here to bypass that restriction.\n",
    "# Source: https://stackoverflow.com/a/62028209 \n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "req = requests.get(\"https://www.homedepot.com/c/site_map\", headers=headers)\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "sitemap = []\n",
    "all_links = soup.find_all('a')\n",
    "for a in all_links:\n",
    "    sitemap.append(a.text)\n",
    "\n",
    "db = Chroma.from_texts(sitemap, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configure the prompt\n",
    "\n",
    "I will create a prompt template that will be applied to every query passed to the bot. The template provides the bot guidelines on how to answer the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "\n",
    "query = \"Can you suggest a power drill?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt guidelines\n",
    "\n",
    "guidelines = \"\"\"\n",
    "\n",
    "If the query is not related to services or products offered by Home Depot, say you can't help.\n",
    "If the query is asking about a specific product available at Home Depot, look for the product.\n",
    "If the query is not about a specific product, offer the customer some general advice and suggest a few related Home Depot products.\n",
    "If you don't know the answer, say you don't know and provide contact information for customer service.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Set prompt template\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful shop assistant at Home Depot. This is a query from a Home Depot customer: {query}\n",
    "\n",
    "Answer the query following these guidelines: {guidelines}\n",
    "\n",
    "In your answer:\n",
    "Explain your answer briefly.\n",
    "When you mention specific products, use full product names.\n",
    "If you are asked about one specific product and you found the product, provide a link to that product.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\", \"guidelines\"])\n",
    "prompt_str = prompt.format(query=query, guidelines=guidelines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create chains and tools\n",
    "\n",
    "The bot uses different tools to gather the necessary information for answering the query. Each tool consists of a RetrievalQA chain.\n",
    "\n",
    "The chains employ language models with varying temperatures, which determine the level of randomness in the generated answers based on the tool's objective. For the tools `get_products` and `get_details`, a zero-temperature LLM model (`llm_doc`) is used to ensure that answers are generated based on the information from the vector store without any 'creative' answers. On the other hand, for other tools, a medium-temperature LLM model called (`llm`) is used to ensure that the answers align with both the semantic and *pragmatic* meaning of the query.\n",
    "\n",
    "The prompts are modified and fed into the chains to ensure that the answers generated are relevant to the objectives of the tools.\n",
    "\n",
    "> **Notes**\n",
    "> \n",
    "> - To ensure a high accuracy, the bot needs to get the most up-to-date information from Home Depot in real time. Therefore, I decided not to pre-scrape Home Depot's website, but instead scrape only the relavant information based on the query.\n",
    ">\n",
    "> - Tool `get_products`: SerpAPI is used to perform a search through Home Depot's search engine. Structured information on search result pages is scraped.\n",
    ">\n",
    "> - Tool `get_details`: The tool aims to extract detailed information about a product. However, Home Depot's product detail pages are generated dynamically with javascript. To scrape these pages, one needs to first render the javascript code. The tool `get_details` employs a web driver to render the page, though it is not fully automated: due to the website's responsive design, manual scrolling down the page is necessary during the rendering process to trigger the JavaScript code. Therefore, this tool will not funciton properly outside the development environment. Unfortunately, I have very limited experience in web development and did not have enough time to come up with a solution. Moreoever, it seems that no third-party API service is able to scrape these pages (I have tried Apify and it failed to render the entire page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chains and functions\n",
    "\n",
    "# Create a chain instance\n",
    "chain = RetrievalQA.from_chain_type(llm=llm_doc, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "\n",
    "# Cheeck if url is valid\n",
    "def check_url(url):\n",
    "    valid=validators.url(url)\n",
    "    if valid==True:\n",
    "        try:\n",
    "            # Headers to bypass server restrictions\n",
    "            headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}       \n",
    "            response = requests.head(url,headers=headers)         \n",
    "            if response.status_code == 200:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except requests.ConnectionError as e:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Create tools from functions\n",
    "\n",
    "@tool\n",
    "def is_homedepot(query):\n",
    "    \"\"\"\n",
    "    Decide whether the query is asking about a product available at Home Depot \n",
    "    query : customer query\n",
    "    \"\"\"\n",
    "    prompt_new = 'Is the following asking about a product available at Home Depot? ' + query\n",
    "    chain_new = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "    ans = chain_new.run(prompt_new)\n",
    "    return ans\n",
    "\n",
    "@tool\n",
    "def get_keyword(query):\n",
    "    \"\"\"\n",
    "    Get the search keyword from the query.\n",
    "    query : customer query\n",
    "    \"\"\"\n",
    "    prompt_new = 'What is the product mentioned in the query? ' + query\n",
    "    chain_new = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "    ans = chain_new.run(prompt_new) \n",
    "    return ans\n",
    "\n",
    "@tool\n",
    "def get_products(keyword):\n",
    "    \"\"\"\n",
    "    Searches for the keyword at Home Depot. Add results to vector store.\n",
    "    keyword : Search keyword\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "    \"engine\": \"home_depot\",\n",
    "    \"api_key\": SERPAPI_API_KEY,\n",
    "    \"q\": keyword\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    if \"products\" in search.get_dict().keys():\n",
    "        products = search.get_dict()[\"products\"]\n",
    "    else:\n",
    "        ans = chain.run(prompt_str)\n",
    "        return ans\n",
    "    \n",
    "    ######################################################    \n",
    "    # Clean the search results\n",
    "\n",
    "    # drop unused product info\n",
    "    for p in products:\n",
    "        for key in ['position', 'thumbnails', 'serpapi_link', 'collection', 'variants']:\n",
    "            if key in p.keys():\n",
    "                del p[key]\n",
    "    \n",
    "    # Embedding models only work on texts or numbers. Fix values other than str, int or float.\n",
    "    for p in products:\n",
    "        for k,v in p.items():\n",
    "            # Change value to 'none' if it's not str/int/float or list/bool (will take care of these later)\n",
    "            if type(v) not in [str, int, float, list, bool]:\n",
    "                p[k] = 'none'\n",
    "            # Convert list of strings to string\n",
    "            if type(v)==list:\n",
    "                p[k] = '-'.join(v)\n",
    "            # Convert boolean to string\n",
    "            if type(v)==bool:\n",
    "                if p[k]==True:\n",
    "                    p[k] = 'true'\n",
    "                else:\n",
    "                    p[k] = 'false'\n",
    "\n",
    "    # Vector stores do not accept nested dict as metadata. Need to flatten it.\n",
    "    for p in range(len(products)):\n",
    "        # flatten each dict in products\n",
    "        p_flatdict = flatdict.FlatDict(products[p], delimiter='.')\n",
    "        # convert flatdict back to dict\n",
    "        p_dict = {}\n",
    "        for i in p_flatdict.iteritems():\n",
    "            p_dict.update({i})\n",
    "            products[p] = p_dict\n",
    "    \n",
    "    ######################################################\n",
    "    # Add search results to vector store\n",
    "\n",
    "    # Get a list of product names (will be used as the texts for vector stores)\n",
    "    product_names = [p['title'] for p in products]\n",
    "\n",
    "    # Add texts to vector store\n",
    "    global db  # assess db outside the function\n",
    "    db.add_texts(product_names, metadatas=products)\n",
    "\n",
    "    ans = chain.run(prompt_str)\n",
    "    return ans\n",
    "\n",
    "@tool\n",
    "def get_details(link):\n",
    "    \"\"\"\n",
    "    Get product details from the link. Add results to vector store.\n",
    "    link : link to product detail page\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate link url\n",
    "    if not check_url(link): return \"Please provide more information.\"\n",
    "     \n",
    "    # Use webdriver to load the page\n",
    "    driver = webdriver.Chrome('./chromedriver') \n",
    "    driver.get(link)    \n",
    "    time.sleep(20)  # give extra time to ensure that the page is fully rendered    \n",
    "    page = driver.page_source\n",
    "\n",
    "    # Scrape texts on page\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    name = soup.find('div', {'class': 'product-details__badge-title--wrapper'}).text\n",
    "    ids = soup.find('div', {'class': 'sui-flex sui-text-xs sui-flex-wrap'}).text\n",
    "    overview = soup.find('section', {'id': 'product-section-product-overview'}).text\n",
    "    specs = soup.find('section', {'id': 'specifications-desktop'}).text\n",
    "\n",
    "    # Close webdriver after scraping\n",
    "    driver.close()\n",
    "\n",
    "    # clean the data\n",
    "    overview = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", overview)\n",
    "    specs = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", specs)\n",
    "    specs = re.sub('See Similar Items', ' ', specs)\n",
    "    ids = re.sub('Internet', ' Internet:', ids)\n",
    "    ids = re.sub('Model', ' Model:', ids)\n",
    "    ids = re.sub('Store SKU', ' Store SKU:', ids)\n",
    "    ids = re.sub('Store SO SKU', ' Store SO SKU:', ids)\n",
    "\n",
    "    # Concatenate scraped texts into a string\n",
    "    pdp = 'Product Name: ' + name + '\\nProduct IDs: ' + ids + '\\nProduct Overview: ' + overview + '\\nSpecifications: ' + specs\n",
    "\n",
    "    # Add text to vector store\n",
    "    global db  # assess db outside the function\n",
    "    db.add_texts(pdp)\n",
    "    \n",
    "    ans = chain.run(prompt_str)\n",
    "    return ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create an agent\n",
    "\n",
    "The bot contains an agent that decides the tools to be used to get the information needed to answer the query. Note that the agent takes in the query directly without the prompt template applied. Besides, a medium-temprature language model (`llm`) is employed with no access to external information or the vector store. \n",
    "\n",
    "The bot incorporates an agent responsible for selecting the appropriate tools to gather the necessary information for answering a query. It's important to note that the agent receives the query directly without the prompt template applied. Additionally, a medium-temperature language model (`llm`) is employed and the agent has no access to external information or the vector store. Such measures provide the agent with a sufficient degree of freedom to make the best decision based solely on the query and the tool descriptions.\n",
    "\n",
    "Therefore, the bot initially focuses on gathering sufficient information using the available tools before receiving instructions on how to answer specific questions through prompt templates.\n",
    "\n",
    "The figure below illustrates the structure of the bot:\n",
    "\n",
    "![structure](/bot_structure.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m First, I need to know if the suggested power drill is available at Home Depot.\n",
      "Action: is_homedepot\n",
      "Action Input: suggested power drill\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "Yes\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Okay, now I need to find power drills at Home Depot.\n",
      "Action: get_products\n",
      "Action Input: power drills\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "I can help you with that. Home Depot offers a wide variety of power drills, including cordless, corded, and hammer drills. If you're looking for a cordless drill, I recommend the DeWalt 20V Max Cordless Drill. It's a powerful and versatile drill that's perfect for a variety of tasks. If you're not sure what type of drill you need, or if you have any questions, you can contact Home Depot customer service at 1-800-HOME-DEPOT (1-800-466-3337).\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "I can help you with that. Home Depot offers a wide variety of power drills, including cordless, corded, and hammer drills. If you're looking for a cordless drill, I recommend the DeWalt 20V Max Cordless Drill. It's a powerful and versatile drill that's perfect for a variety of tasks. If you're not sure what type of drill you need, or if you have any questions, you can contact Home Depot customer service at 1-800-HOME-DEPOT (1-800-466-3337).\n"
     ]
    }
   ],
   "source": [
    "# Create an agent with tools\n",
    "\n",
    "tools = [\n",
    "\n",
    "    Tool(\n",
    "        name = \"is_homedepot\",\n",
    "        func=is_homedepot,\n",
    "        description=\"Use this tool if you are not sure the query is asking about a specific product available at Home Depot. Input is the query\",        \n",
    "    ),\n",
    "\n",
    "    Tool(\n",
    "        name = \"get_products\",\n",
    "        func=get_products,\n",
    "        description=\"Look for the products on Home Depot's website. Input is a string.\",\n",
    "        return_direct=True\n",
    "    ),\n",
    "\n",
    "    Tool(\n",
    "        name = \"get_details\",\n",
    "        func=get_details,\n",
    "        description=\"Find the product details about a specific product. The input is the link to the product. You can get this link from the search results you got from the function 'get_products'\",\n",
    "        return_direct=True\n",
    "    )\n",
    "\n",
    "]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
    "print(agent.run(query))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
